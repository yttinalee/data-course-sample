{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yttinalee/data-course-sample/blob/main/Week3_A6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ve2XNVh88en1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import gzip, json\n",
        "\n",
        "def parse(path):\n",
        "    g = gzip.open(path, 'rb')\n",
        "    for l in g:\n",
        "        yield json.loads(l)\n",
        "\n",
        "def getDF(path):\n",
        "    i = 0\n",
        "    df = {}\n",
        "    for d in parse(path):\n",
        "        df[i] = d\n",
        "        i += 1\n",
        "    return pd.DataFrame.from_dict(df, orient='index')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iuzrlioj8en3",
        "outputId": "0fa0a928-b73e-4dd8-a630-8cfd67885021"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'wget' ���O�����Υ~���R�O�B�i���檺�{���Χ妸�ɡC\n",
            "'wget' ���O�����Υ~���R�O�B�i���檺�{���Χ妸�ɡC\n"
          ]
        }
      ],
      "source": [
        "!wget http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/All_Beauty.csv\n",
        "!wget http://deepyeti.ucsd.edu/jianmo/amazon/metaFiles2/meta_All_Beauty.json.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xmd0ojs8en4"
      },
      "outputs": [],
      "source": [
        "metadata = getDF('../S2/meta_All_Beauty.json.gz')\n",
        "ratings = pd.read_csv('http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/All_Beauty.csv', names=['asin', 'reviewerID', 'overall', 'unixReviewTime'], header=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_NSk0Cn8en5"
      },
      "outputs": [],
      "source": [
        "ratings['DATE'] = pd.to_datetime(ratings['unixReviewTime'], unit='s')\n",
        "ratings_trainings = ratings[\n",
        "    (ratings['DATE'] < '2018-09-01')\n",
        "]\n",
        "ratings_testings = ratings[\n",
        "    (ratings['DATE'] >= '2018-09-01') & \n",
        "    (ratings['DATE'] <= '2018-09-30')\n",
        "]\n",
        "ratings_trainings_by_user = ratings_trainings.groupby('reviewerID').agg(list).reset_index()[['reviewerID', 'asin']].to_dict('records')\n",
        "ratings_trainings_by_user = { rating['reviewerID']: rating['asin'] for rating in ratings_trainings_by_user }\n",
        "training_users = list(ratings_trainings_by_user.keys())\n",
        "ratings_testings_by_user = ratings_testings.groupby('reviewerID').agg(list).reset_index()[['reviewerID', 'asin']].to_dict('records')\n",
        "ratings_testings_by_user = { rating['reviewerID']: rating['asin'] for rating in ratings_testings_by_user }\n",
        "users = list(ratings_testings_by_user.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUJTj6hU8en5"
      },
      "outputs": [],
      "source": [
        "same_user = set(training_users)&set(users)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApBp5Xk08en6"
      },
      "outputs": [],
      "source": [
        "notsame_user = set(users)^set(same_user)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G04q7mx78en6",
        "outputId": "f1f9dfe1-7f8f-4c80-aee1-d705fe22df3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": "(546, 584)"
          },
          "execution_count": 187,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(notsame_user), len(users)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SXkCqLlx8en6"
      },
      "outputs": [],
      "source": [
        "ratings_trainings_by_asin = ratings_testings.groupby('asin').agg(list).reset_index()['asin']\n",
        "# ratings_trainings_by_asin = { rating['reviewerID']: rating['asin'] for rating in ratings_trainings_by_user }\n",
        "# training_asins = list(ratings_trainings_by_user.keys())\n",
        "ratings_testings_by_asin = ratings_testings.groupby('asin').agg(list).reset_index()['asin']\n",
        "# ratings_testings_by_asin = { rating['reviewerID']: rating['asin'] for rating in ratings_testings_by_user }\n",
        "# asins = list(ratings_testings_by_user.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPsNqZGe8en6",
        "outputId": "45d6b2b1-de04-4c80-a000-873947aa144c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": "335"
          },
          "execution_count": 189,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# # training data中的asin有多少也出現在testint data\n",
        "same_asin = set(ratings_trainings_by_asin)&set(ratings_testings_by_asin)\n",
        "len(same_asin)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FZR2WX4N8en7"
      },
      "outputs": [],
      "source": [
        "category = metadata['rank'].str.split(' in ', expand=True)\n",
        "category = category.rename(columns={category.columns[0]:'ranking', category.columns[1]:'categories'})\n",
        "# category.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-twuRJD8en7"
      },
      "outputs": [],
      "source": [
        "category['ranking'] = category['ranking'].str.replace(',','')\n",
        "category['categories'] = category['categories'].str.replace('amp;','')\n",
        "category['categories'] = category['categories'].str.replace('\\(', '')\n",
        "category['ranking'] = pd.to_numeric(category['ranking'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XzJxedQ08en7"
      },
      "outputs": [],
      "source": [
        "meta_use = metadata[['asin', 'title', 'also_buy', 'brand', 'rank', 'also_view', 'details', 'price', 'description']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F4oJ-hSc8en7",
        "outputId": "433ed6dc-1242-4e3d-f67f-318aeec97b27"
      },
      "outputs": [
        {
          "data": {
            "text/plain": "asin\nB00026KYLM    2\nB00021DI10    2\nB00021CWYO    2\nB00021CQTA    2\nB00021CPNC    2\n             ..\nB01172CGQK    1\nB01172N21I    1\nB01172N2HM    1\nB01174YHM4    1\n6546546450    1\nName: title, Length: 32488, dtype: int64"
          },
          "execution_count": 193,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "meta_use.groupby('asin').count()['title'].sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJ4Ew_Ff8en7",
        "outputId": "b2b46cb0-7dff-456b-801b-8b6b7aea9726"
      },
      "outputs": [
        {
          "data": {
            "text/plain": "brand\nNeuOra Microceuticals                                       1\nNeugaugh                                                    1\nNippon Kodo                                                 1\nNjoy, Wicked                                                1\nNo Boundries                                                1\nNo Nix                                                      1\nNo Turn                                                     1\nNoCry                                                       1\nNoix D'Or                                                   1\nNok Out                                                     1\nNomaterra                                                   1\nNoogleberry                                                 1\nNorelco 6701X Cool Skin Additive In/Out of Shower Shaver    1\nNoreva                                                      1\nNorth American Hemp Company                                 1\nNorth American Herb & Spice                                 1\nNorth Coast Medical                                         1\nNorth Safety                                                1\nNorthern Star                                               1\nNorthwest Scents                                            1\nNot Your Mother's                                           1\nNothing But Quality, Ching Ching                            1\nNougat                                                      1\nNourish Organic                                             1\nNitiraj                                                     1\nNikken                                                      1\nNeutralab                                                   1\nNightingale Conant                                          1\nNevissbags                                                  1\nNew Age Source                                              1\nNew Brand                                                   1\nNew Era                                                     1\nNew World Music                                             1\nNew York Orthopedic                                         1\nNew York Orthopedic USA                                     1\nNewhouse Specialty Co                                       1\nNexsey                                                      1\nNexus                                                       1\nNice Dreams                                                 1\nNick & Nora                                                 1\nNick Chavez                                                 1\nNicka K                                                     1\nNickel Skincare for Men                                     1\nNickelodeon                                                 1\nNicki Minaj                                                 1\nNicki Minaj Minajesty                                       1\nNicole Miller                                               1\nNicorobin                                                   1\nNigella Therapy                                             1\nLeggings                                                    1\nName: title, dtype: int64"
          },
          "execution_count": 194,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "meta_use.groupby('brand').count()['title'].sort_values(ascending=False).tail(50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uaLudUbR8en8",
        "outputId": "b2f99914-03bb-4876-a91c-843497d7b137"
      },
      "outputs": [
        {
          "data": {
            "text/plain": "title\nBaubax Women's Bomber Travel Jacket                                                                                                                                                          9\nBourjois Healthy Mix Foundation                                                                                                                                                              7\nDerma Roller 0.25mm - Facial Skin Care Tool for Face - Micro Needle Roller - 540 Deluxe Titanium Micro Needles - Titanium Microneedle Roller - Perfect Cosmetic Microneedling Skin Roller    7\nSankuwen 15PCs Wool Makeup Brush Set Tools Toiletry Kit                                                                                                                                      7\n2                                                                                                                                                                                            5\nBMC Nail Art Water Transfer Tattoo Effects Decoration Decal-Peacock French Tips2                                                                                                             5\nDonna Premium Collection Extra Firm Mesh Wrap                                                                                                                                                4\nMen's Shoulder Bag,Kangaroo                                                                                                                                                                  4\nAfricana - 6ml (.2 oz) Perfume Oil by Al-Rehab (Crown Perfumes) by Al-Rehab                                                                                                                  4\nBuytra Cat Canvas Student Pen Pencil Case Coin Purse Pouch Cosmetic Makeup Bag                                                                                                               4\nName: asin, dtype: int64"
          },
          "execution_count": 195,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "meta_use.groupby('title').count()['asin'].sort_values(ascending=False).head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GY3xXQx8en8",
        "outputId": "213e3da1-d20b-43f3-e271-6127a9c28f4b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-196-4095d30288ae>:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  meta_use['ranking'] = category['ranking']\n",
            "<ipython-input-196-4095d30288ae>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  meta_use['categories'] = category['categories']\n",
            "<ipython-input-196-4095d30288ae>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  meta_use['title'] = meta_use['title'].str.replace('&amp;','')\n"
          ]
        }
      ],
      "source": [
        "meta_use['ranking'] = category['ranking']\n",
        "meta_use['categories'] = category['categories']\n",
        "meta_use['title'] = meta_use['title'].str.replace('&amp;','')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PLqPPzB8en8",
        "outputId": "998c5952-04ba-424b-e6ea-afdf8e6b1f00"
      },
      "outputs": [
        {
          "data": {
            "text/plain": "(32300,\n 32892,\n 0        Loud 'N Clear&trade; Personal Sound Amplifier\n 1    No7 Lift  Luminate Triple Action Serum 50ml by...\n 2      No7 Stay Perfect Foundation Cool Vanilla by No7\n 3    Wella Koleston Perfect Hair Colour 44/44 Mediu...\n 4    Lacto Calamine Skin Balance Oil control 120 ml...\n 5    Mary Kay Satin Hands Hand Cream Travel MINI Si...\n 6    Unique Custom Cast Iron Liner Shader Tattoo Ma...\n Name: title, dtype: object)"
          },
          "execution_count": 197,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(meta_use['title'].unique()), len(meta_use['title']), meta_use['title'].head(7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2uNP-JVm8en8",
        "outputId": "1ec27837-679c-46cb-e0fa-68626338f25d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": "(323489, 370752, 323489)"
          },
          "execution_count": 198,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(ratings_trainings['reviewerID'].unique()), len(ratings_trainings['reviewerID']), len(ratings_trainings.groupby(['reviewerID']).count()>1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0OmzOdUE8en8"
      },
      "outputs": [],
      "source": [
        "training_users_2uper_uni = ratings_trainings.groupby(['reviewerID']).count()['asin'][ratings_trainings.groupby(['reviewerID']).count()['asin']>1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlgYbBgy8en9"
      },
      "outputs": [],
      "source": [
        "a = []\n",
        "for ID in range(0, len(ratings_trainings['reviewerID'])):\n",
        "  if ratings_trainings['reviewerID'].iloc[ID] in training_users_2uper_uni:\n",
        "    a.append(ID)\n",
        "ratings_trainings_remove1 = ratings_trainings.iloc[a]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3wOxDBT8en9",
        "outputId": "c2b92cb3-2aec-46b9-a8e3-712390e7ad3c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": "(36222, 83485)"
          },
          "execution_count": 201,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(ratings_trainings_remove1['reviewerID'].unique()), len(ratings_trainings_remove1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMR7T-Lq8en9"
      },
      "outputs": [],
      "source": [
        "ratings_users_uni = ratings.groupby(['reviewerID']).count()['asin'][ratings.groupby(['reviewerID']).count()['asin']>1]\n",
        "a = []\n",
        "for ID in range(0, len(ratings['reviewerID'])):\n",
        "  if ratings['reviewerID'].iloc[ID] in ratings_users_uni:\n",
        "    a.append(ID)\n",
        "ratings_trainings_remove1_surprise= ratings.iloc[a]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2FtefUx8en9",
        "outputId": "960be145-f56f-45ff-f6be-95a1c5bfc7e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": "83561"
          },
          "execution_count": 203,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(ratings_trainings_remove1_surprise)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QaGCtEVr8en9"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import string \n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "df = meta_use.drop_duplicates(['asin', 'title', 'brand'])\n",
        "\n",
        "def preproc(sentence):\n",
        "# for sentence in range(0, len(meta_use['title'])):\n",
        "  remove_punctuation = ''.join([i for i in sentence if i not in string.punctuation]).lower()\n",
        "  tokens = word_tokenize(remove_punctuation)\n",
        "  result = [lemmatizer.lemmatize(word) for word in tokens if not word in stopwords.words('english')]\n",
        "  return ' '.join(result)\n",
        "\n",
        "df['title'].apply(lambda x: preproc(x))\n",
        "# 計算商品用標題所表示的 tfidf 矩陣\n",
        "\n",
        "tf = TfidfVectorizer(analyzer='word')\n",
        "tfidf_matrix = tf.fit_transform(df['title'])\n",
        "\n",
        "# 計算商品間的相似程度\n",
        "similarity_matrix = cosine_similarity(tfidf_matrix)\n",
        "mapping = pd.Series(df.index,index = df['title'])\n",
        "\n",
        "# # 每個商品回傳 k 個最相近的商品\n",
        "def recommend_item(item_input, k=2):\n",
        "    try:\n",
        "        item_index = mapping[item_input]\n",
        "        similarity_score = list(enumerate(similarity_matrix[item_index]))\n",
        "        similarity_score = sorted(similarity_score, key=lambda x: x[1], reverse=True)\n",
        "        similarity_score = similarity_score[:k]\n",
        "        item_indices = [i[0] for i in similarity_score]\n",
        "        return (df['asin'].iloc[item_indices].tolist())\n",
        "    except:\n",
        "        return []\n",
        "\n",
        "# # 利用使用者購買過的商品產生推薦\n",
        "def recommend_items(items, k):\n",
        "    res = []\n",
        "    for d in items:\n",
        "        res.extend(recommend_item(d, k))\n",
        "    return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j8z8d2sX8en-"
      },
      "outputs": [],
      "source": [
        "limitTime_training_data = ratings_trainings[(ratings_trainings['DATE'] >= '2018-05-31') &  (ratings_trainings['DATE'] <= '2018-09-01')]\n",
        "top_10 = limitTime_training_data.groupby('asin').size().sort_values(ascending=False).index.to_list()[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEkT4ZVA8en-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from itertools import combinations\n",
        "from collections import defaultdict\n",
        "\n",
        "def recommender_user(training_data, users=[], k=10):\n",
        "\n",
        "    # loading data from dataframe\n",
        "    # item_to_users dict:\n",
        "    # {\n",
        "    #   'item': {\n",
        "    #       'user': ratings...\n",
        "    #   }...\n",
        "    # }\n",
        "    item_to_users = defaultdict(dict)\n",
        "    for _, row in training_data.iterrows():\n",
        "        row = dict(row)\n",
        "        user = row['reviewerID']\n",
        "        item = row['asin']\n",
        "        rating = float(row['overall'])\n",
        "        item_to_users[item][user] = rating\n",
        "\n",
        "    # print(\"data converted\")\n",
        "\n",
        "    user_to_items = defaultdict(dict)\n",
        "    for item, rating_users in item_to_users.items():\n",
        "        for user, rating in rating_users.items():\n",
        "            user_to_items[user][item] = rating\n",
        "\n",
        "    # print(\"data inverted\")\n",
        "\n",
        "    init_sim = lambda: [0, 0, 0]\n",
        "    factory = lambda: defaultdict(init_sim)\n",
        "    pre_item_similarity = defaultdict(factory)\n",
        "    for user, items in user_to_items.items():\n",
        "        if len(items) > 1:\n",
        "            for i1, i2 in combinations(items.keys(), 2):\n",
        "                xy = items[i1] * items[i2]\n",
        "                xx = items[i1] ** 2\n",
        "                yy = items[i2] ** 2\n",
        "                pre_item_similarity[i1][i2][0] += xy\n",
        "                pre_item_similarity[i1][i2][1] += xx\n",
        "                pre_item_similarity[i1][i2][2] += yy\n",
        "\n",
        "                pre_item_similarity[i2][i1][0] += xy\n",
        "                pre_item_similarity[i2][i1][1] += xx\n",
        "                pre_item_similarity[i2][i1][2] += yy\n",
        "\n",
        "    # print(\"sim data prepared\")\n",
        "\n",
        "    item_similarity = {}\n",
        "    for src_item in pre_item_similarity:\n",
        "        item_similarity_order = []\n",
        "        for dst_item, val in pre_item_similarity[src_item].items():\n",
        "            xy = val[0]\n",
        "            xx = val[1]\n",
        "            yy = val[2]\n",
        "            div = ((xx*yy) ** 0.5)\n",
        "            if div == 0:\n",
        "                continue\n",
        "            similarity = xy / div\n",
        "            if similarity < 0:\n",
        "                continue\n",
        "            for i, s in enumerate(item_similarity_order):\n",
        "                target_similarity = s[1]\n",
        "                if target_similarity < similarity:\n",
        "                    item_similarity_order.insert(i, (dst_item, similarity))\n",
        "                    break\n",
        "            else:\n",
        "                item_similarity_order.append((dst_item, similarity))\n",
        "        item_similarity[src_item] = item_similarity_order\n",
        "\n",
        "    # print(f\"get {k} recommendation items for for user: {users}\")\n",
        "\n",
        "    recommendation = {}\n",
        "    for user in users:\n",
        "        items = []\n",
        "        items_set = set()\n",
        "        stop = False\n",
        "        user_has_rated = set(user_to_items[user])\n",
        "        for item in user_has_rated:\n",
        "            if item in item_similarity:\n",
        "                for sim_item, _ in item_similarity[item]:\n",
        "                    # skip the item user has rated\n",
        "                    if sim_item not in user_has_rated and sim_item not in items_set:\n",
        "                        items.append(sim_item)\n",
        "                        items_set.add(sim_item)\n",
        "                    if len(items) >= k:\n",
        "                        stop = True\n",
        "                        break\n",
        "                if stop:\n",
        "                    break\n",
        "        recommendation[user] = items\n",
        "    return recommendation \n",
        "\n",
        "def recommender_item(training_data, users=[], k=10):\n",
        "\n",
        "    # loading data from dataframe\n",
        "    # item_to_users dict:\n",
        "    # {\n",
        "    #   'item': {\n",
        "    #       'user': ratings...\n",
        "    #   }...\n",
        "    # }\n",
        "    item_to_users = defaultdict(dict)\n",
        "    for _, row in training_data.iterrows():\n",
        "        row = dict(row)\n",
        "        user = row['reviewerID']\n",
        "        item = row['asin']\n",
        "        rating = float(row['overall'])\n",
        "        item_to_users[item][user] = rating\n",
        "\n",
        "    # print(\"data converted\")\n",
        "\n",
        "    user_to_items = defaultdict(dict)\n",
        "    for item, rating_users in item_to_users.items():\n",
        "        for user, rating in rating_users.items():\n",
        "            user_to_items[user][item] = rating\n",
        "\n",
        "    # print(\"data inverted\")\n",
        "\n",
        "    init_sim = lambda: [0, 0, 0]\n",
        "    factory = lambda: defaultdict(init_sim)\n",
        "    pre_item_similarity = defaultdict(factory)\n",
        "    for user, items in user_to_items.items():\n",
        "        if len(items) > 1:\n",
        "            for i1, i2 in combinations(items.keys(), 2):\n",
        "                xy = items[i1] * items[i2]\n",
        "                xx = items[i1] ** 2\n",
        "                yy = items[i2] ** 2\n",
        "                pre_item_similarity[i1][i2][0] += xy\n",
        "                pre_item_similarity[i1][i2][1] += xx\n",
        "                pre_item_similarity[i1][i2][2] += yy\n",
        "\n",
        "                pre_item_similarity[i2][i1][0] += xy\n",
        "                pre_item_similarity[i2][i1][1] += xx\n",
        "                pre_item_similarity[i2][i1][2] += yy\n",
        "\n",
        "    # print(\"sim data prepared\")\n",
        "\n",
        "    item_similarity = {}\n",
        "    for src_item in pre_item_similarity:\n",
        "        item_similarity_order = []\n",
        "        for dst_item, val in pre_item_similarity[src_item].items():\n",
        "            xy = val[0]\n",
        "            xx = val[1]\n",
        "            yy = val[2]\n",
        "            div = ((xx*yy) ** 0.5)\n",
        "            if div == 0:\n",
        "                continue\n",
        "            similarity = xy / div\n",
        "            if similarity < 0:\n",
        "                continue\n",
        "            for i, s in enumerate(item_similarity_order):\n",
        "                target_similarity = s[1]\n",
        "                if target_similarity < similarity:\n",
        "                    item_similarity_order.insert(i, (dst_item, similarity))\n",
        "                    break\n",
        "            else:\n",
        "                item_similarity_order.append((dst_item, similarity))\n",
        "        item_similarity[src_item] = item_similarity_order\n",
        "\n",
        "    # print(f\"get {k} recommendation items for for user: {users}\")\n",
        "\n",
        "    recommendation = {}\n",
        "    for user in users:\n",
        "        items = []\n",
        "        items_set = set()\n",
        "        stop = False\n",
        "        user_has_rated = set(user_to_items[user])\n",
        "        for item in user_has_rated:\n",
        "            if item in item_similarity:\n",
        "                for sim_item, _ in item_similarity[item]:\n",
        "                    # skip the item user has rated\n",
        "                    if sim_item not in user_has_rated and sim_item not in items_set:\n",
        "                        items.append(sim_item)\n",
        "                        items_set.add(sim_item)\n",
        "                    if len(items) >= k:\n",
        "                        stop = True\n",
        "                        break\n",
        "                if stop:\n",
        "                    break\n",
        "        recommendation[user] = items\n",
        "    return recommendation\n",
        "\n",
        "import time\n",
        "import pandas as pd\n",
        "from surprise import Reader\n",
        "from surprise import Dataset\n",
        "from surprise import KNNBasic\n",
        "\n",
        "def recommender_surprise(training_data, users=[], k=10, user_based=False, algo=KNNBasic):\n",
        "\n",
        "    training_data = training_data[(training_data['DATE'] >= '2016-08-31') &  (training_data['DATE'] <= '2018-09-30')]\n",
        "\n",
        "    training_data = (\n",
        "        training_data\n",
        "        .sort_values(\"DATE\", ascending=False)\n",
        "        .groupby(['reviewerID', 'asin']).head(1)\n",
        "    )\n",
        "\n",
        "    reader = Reader(rating_scale=(0, 5))\n",
        "    training_data = training_data[['reviewerID', 'asin', 'overall']]\n",
        "    data = Dataset.load_from_df(training_data, reader=reader)\n",
        "\n",
        "    sim_options = {\n",
        "        'name': 'cosine',\n",
        "        'user_based': user_based  # compute similarities between items\n",
        "    }\n",
        "    algo_impl = algo(sim_options=sim_options)\n",
        "    trainset = data.build_full_trainset()\n",
        "    algo_impl.fit(trainset)\n",
        "\n",
        "    recommendation = {}\n",
        "    for user in users:\n",
        "        items_user_rated = set(training_data.loc[training_data['reviewerID'] == user]['asin'].to_list())\n",
        "        recommend_item_list = []\n",
        "        recommend_item_set = set()\n",
        "        for item in items_user_rated:\n",
        "            iid = algo_impl.trainset.to_inner_iid(item)\n",
        "            recommend_items_iid = algo_impl.get_neighbors(iid, k)\n",
        "            for sim_item_iid in recommend_items_iid:\n",
        "                item_raw_id = algo_impl.trainset.to_raw_iid(sim_item_iid)\n",
        "                if item_raw_id not in items_user_rated and item_raw_id not in recommend_item_set:\n",
        "                    recommend_item_list.append(item_raw_id)\n",
        "                    recommend_item_set.add(item_raw_id)\n",
        "\n",
        "            if len(recommend_item_list) >= k:\n",
        "                recommend_item_list = recommend_item_list[:k]\n",
        "                break\n",
        "        recommendation[user] = recommend_item_list\n",
        "\n",
        "    return recommendation     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JmBrGiz68eoA"
      },
      "outputs": [],
      "source": [
        "def evaluate(ratings_testings_by_user={}, ratings_by_user={}, method=None):\n",
        "    '''\n",
        "    * ratings_testings_by_user: dict 真實被購買的商品資料（2018-09-01 以後資料）\n",
        "    * ratings_by_user: dict 利用訓練資料學習的推薦商品\n",
        "    * method: str\n",
        "    * score: float\n",
        "    '''\n",
        "    total = 0\n",
        "    for d in ratings_testings_by_user:\n",
        "        if d in ratings_by_user:\n",
        "            total += len(set(ratings_by_user[d]) & set(ratings_testings_by_user[d]))\n",
        "    score = total / len(ratings_testings)\n",
        "    return score\n",
        "# evaluate(ratings_testings_by_user, ratings_by_user)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Az0HkhQW8eoB",
        "outputId": "47e38461-4517-46cf-9d52-460a17e27a5f"
      },
      "outputs": [
        {
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>recommender_list</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.001695</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.001695</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "  recommender_list     score\n0                0  0.001695\n1                1  0.001695"
          },
          "execution_count": 208,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Test only user-based or item-based results\n",
        "evaluate_result = {}\n",
        "n = 0\n",
        "R = [recommender_user, recommender_item]  \n",
        "for recommender in R: \n",
        "  ratings_by_user = {}\n",
        "  # print(ratings_by_user)\n",
        "  ratings_by_user = recommender(ratings_trainings, users)\n",
        "  evaluate_result[str(n)] = evaluate(ratings_testings_by_user, ratings_by_user)\n",
        "  n += 1\n",
        "result = pd.DataFrame(list(evaluate_result.items()), columns=['recommender_list', 'score'])\n",
        "\n",
        "result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0k5udJW08eoC",
        "outputId": "9a54d925-bf02-4fe8-977a-36dcfb0c1605"
      },
      "outputs": [
        {
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>recommender_list</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "  recommender_list  score\n0                0    0.0\n1                1    0.0"
          },
          "execution_count": 209,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Test user-based or item-based results with ID counts more than 1\n",
        "evaluate_result = {}\n",
        "n = 0\n",
        "R = [recommender_user, recommender_item]  \n",
        "for recommender in R: #\n",
        "  ratings_by_user = {}\n",
        "  # print(ratings_by_user)\n",
        "  ratings_by_user = recommender(ratings_trainings_remove1_surprise, users)  ## using removed only 1 history record ID\n",
        "  evaluate_result[str(n)] = evaluate(ratings_testings_by_user, ratings_by_user)\n",
        "  n += 1\n",
        "result = pd.DataFrame(list(evaluate_result.items()), columns=['recommender_list', 'score'])\n",
        "\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJ5Z6zl38eoC",
        "outputId": "d5b777fe-e9fb-43e1-a459-ee238f62ac7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n"
          ]
        },
        {
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>recommender_list</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.001695</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "  recommender_list     score\n0                0  0.000000\n1                1  0.001695"
          },
          "execution_count": 210,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate_result = {}\n",
        "n = 0\n",
        "R = [recommender_surprise]  \n",
        "train_data = [ratings, ratings_trainings_remove1_surprise]\n",
        "for recommender in R: #\n",
        "  for data in train_data:\n",
        "    ratings_by_user = {}\n",
        "    # print(ratings_by_user)\n",
        "    ratings_by_user = recommender(data, users)  \n",
        "    evaluate_result[str(n)] = evaluate(ratings_testings_by_user, ratings_by_user)\n",
        "    n += 1\n",
        "result = pd.DataFrame(list(evaluate_result.items()), columns=['recommender_list', 'score'])\n",
        "\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CcYlGf398eoC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from itertools import combinations\n",
        "from collections import defaultdict\n",
        "\n",
        "def recommender_user(training_data, users=[], k=10):\n",
        "\n",
        "    # loading data from dataframe\n",
        "    # item_to_users dict:\n",
        "    # {\n",
        "    #   'item': {\n",
        "    #       'user': ratings...\n",
        "    #   }...\n",
        "    # }\n",
        "    item_to_users = defaultdict(dict)\n",
        "    for _, row in training_data.iterrows():\n",
        "        row = dict(row)\n",
        "        user = row['reviewerID']\n",
        "        item = row['asin']\n",
        "        rating = float(row['overall'])\n",
        "        item_to_users[item][user] = rating\n",
        "\n",
        "    # print(\"data converted\")\n",
        "\n",
        "    user_to_items = defaultdict(dict)\n",
        "    for item, rating_users in item_to_users.items():\n",
        "        for user, rating in rating_users.items():\n",
        "            user_to_items[user][item] = rating\n",
        "\n",
        "    # print(\"data inverted\")\n",
        "\n",
        "    init_sim = lambda: [0, 0, 0]\n",
        "    factory = lambda: defaultdict(init_sim)\n",
        "    pre_item_similarity = defaultdict(factory)\n",
        "    for user, items in user_to_items.items():\n",
        "        if len(items) > 1:\n",
        "            for i1, i2 in combinations(items.keys(), 2):\n",
        "                xy = items[i1] * items[i2]\n",
        "                xx = items[i1] ** 2\n",
        "                yy = items[i2] ** 2\n",
        "                pre_item_similarity[i1][i2][0] += xy\n",
        "                pre_item_similarity[i1][i2][1] += xx\n",
        "                pre_item_similarity[i1][i2][2] += yy\n",
        "\n",
        "                pre_item_similarity[i2][i1][0] += xy\n",
        "                pre_item_similarity[i2][i1][1] += xx\n",
        "                pre_item_similarity[i2][i1][2] += yy\n",
        "\n",
        "    # print(\"sim data prepared\")\n",
        "\n",
        "    item_similarity = {}\n",
        "    for src_item in pre_item_similarity:\n",
        "        item_similarity_order = []\n",
        "        for dst_item, val in pre_item_similarity[src_item].items():\n",
        "            xy = val[0]\n",
        "            xx = val[1]\n",
        "            yy = val[2]\n",
        "            div = ((xx*yy) ** 0.5)\n",
        "            if div == 0:\n",
        "                continue\n",
        "            similarity = xy / div\n",
        "            if similarity < 0:\n",
        "                continue\n",
        "            for i, s in enumerate(item_similarity_order):\n",
        "                target_similarity = s[1]\n",
        "                if target_similarity < similarity:\n",
        "                    item_similarity_order.insert(i, (dst_item, similarity))\n",
        "                    break\n",
        "            else:\n",
        "                item_similarity_order.append((dst_item, similarity))\n",
        "        item_similarity[src_item] = item_similarity_order\n",
        "\n",
        "    # print(f\"get {k} recommendation items for for user: {users}\")\n",
        "\n",
        "    recommendation = {}\n",
        "    for user in users:\n",
        "        items = []\n",
        "        items_set = set()\n",
        "        stop = False\n",
        "        user_has_rated = set(user_to_items[user])\n",
        "        for item in user_has_rated:\n",
        "            if item in item_similarity:\n",
        "                for sim_item, _ in item_similarity[item]:\n",
        "                    # skip the item user has rated\n",
        "                    if sim_item not in user_has_rated and sim_item not in items_set:\n",
        "                        items.append(sim_item)\n",
        "                        items_set.add(sim_item)\n",
        "                    if len(items) >= k:\n",
        "                        stop = True\n",
        "                        break\n",
        "                if stop:\n",
        "                    break\n",
        "        recommendation[user] = items\n",
        "  \n",
        "        if len(recommendation[user]) < 10:\n",
        "          recommend_cates = []\n",
        "          recommend_cates = recommend_items(metadata[metadata['asin'].isin(ratings_trainings[ratings_trainings['reviewerID'] == user]['asin'].tolist())]['title'].tolist(), k)\n",
        "          [recommendation[user].append(recommend_cates[gg]) for gg in range(0, len(recommend_cates))]\n",
        "          [recommendation[user].append(top_10[gg]) for gg in range(0, 10-len(recommendation[user]))]\n",
        "    return recommendation    \n",
        "\n",
        "def recommender_item(training_data, users=[], k=10):\n",
        "\n",
        "    # loading data from dataframe\n",
        "    # item_to_users dict:\n",
        "    # {\n",
        "    #   'item': {\n",
        "    #       'user': ratings...\n",
        "    #   }...\n",
        "    # }\n",
        "    item_to_users = defaultdict(dict)\n",
        "    for _, row in training_data.iterrows():\n",
        "        row = dict(row)\n",
        "        user = row['reviewerID']\n",
        "        item = row['asin']\n",
        "        rating = float(row['overall'])\n",
        "        item_to_users[item][user] = rating\n",
        "\n",
        "    # print(\"data converted\")\n",
        "\n",
        "    user_to_items = defaultdict(dict)\n",
        "    for item, rating_users in item_to_users.items():\n",
        "        for user, rating in rating_users.items():\n",
        "            user_to_items[user][item] = rating\n",
        "\n",
        "    # print(\"data inverted\")\n",
        "\n",
        "    init_sim = lambda: [0, 0, 0]\n",
        "    factory = lambda: defaultdict(init_sim)\n",
        "    pre_item_similarity = defaultdict(factory)\n",
        "    for user, items in user_to_items.items():\n",
        "        if len(items) > 1:\n",
        "            for i1, i2 in combinations(items.keys(), 2):\n",
        "                xy = items[i1] * items[i2]\n",
        "                xx = items[i1] ** 2\n",
        "                yy = items[i2] ** 2\n",
        "                pre_item_similarity[i1][i2][0] += xy\n",
        "                pre_item_similarity[i1][i2][1] += xx\n",
        "                pre_item_similarity[i1][i2][2] += yy\n",
        "\n",
        "                pre_item_similarity[i2][i1][0] += xy\n",
        "                pre_item_similarity[i2][i1][1] += xx\n",
        "                pre_item_similarity[i2][i1][2] += yy\n",
        "\n",
        "    # print(\"sim data prepared\")\n",
        "\n",
        "    item_similarity = {}\n",
        "    for src_item in pre_item_similarity:\n",
        "        item_similarity_order = []\n",
        "        for dst_item, val in pre_item_similarity[src_item].items():\n",
        "            xy = val[0]\n",
        "            xx = val[1]\n",
        "            yy = val[2]\n",
        "            div = ((xx*yy) ** 0.5)\n",
        "            if div == 0:\n",
        "                continue\n",
        "            similarity = xy / div\n",
        "            if similarity < 0:\n",
        "                continue\n",
        "            for i, s in enumerate(item_similarity_order):\n",
        "                target_similarity = s[1]\n",
        "                if target_similarity < similarity:\n",
        "                    item_similarity_order.insert(i, (dst_item, similarity))\n",
        "                    break\n",
        "            else:\n",
        "                item_similarity_order.append((dst_item, similarity))\n",
        "        item_similarity[src_item] = item_similarity_order\n",
        "\n",
        "    # print(f\"get {k} recommendation items for for user: {users}\")\n",
        "\n",
        "    recommendation = {}\n",
        "    for user in users:\n",
        "        items = []\n",
        "        items_set = set()\n",
        "        stop = False\n",
        "        user_has_rated = set(user_to_items[user])\n",
        "        for item in user_has_rated:\n",
        "            if item in item_similarity:\n",
        "                for sim_item, _ in item_similarity[item]:\n",
        "                    # skip the item user has rated\n",
        "                    if sim_item not in user_has_rated and sim_item not in items_set:\n",
        "                        items.append(sim_item)\n",
        "                        items_set.add(sim_item)\n",
        "                    if len(items) >= k:\n",
        "                        stop = True\n",
        "                        break\n",
        "                if stop:\n",
        "                    break\n",
        "        recommendation[user] = items\n",
        "        if len(recommendation[user]) < 10:\n",
        "          recommend_cates = []\n",
        "          recommend_cates = recommend_items(metadata[metadata['asin'].isin(ratings_trainings[ratings_trainings['reviewerID'] == user]['asin'].tolist())]['title'].tolist(), k)\n",
        "          [recommendation[user].append(recommend_cates[gg]) for gg in range(0, len(recommend_cates))]\n",
        "          [recommendation[user].append(top_10[gg]) for gg in range(0, 10-len(recommendation[user]))]\n",
        "    return recommendation  \n",
        "\n",
        "import time\n",
        "import pandas as pd\n",
        "from surprise import Reader\n",
        "from surprise import Dataset\n",
        "from surprise import KNNBasic\n",
        "\n",
        "def recommender_surprise(training_data, users=[], k=10, user_based=False, algo=KNNBasic):\n",
        "\n",
        "    training_data = training_data[(training_data['DATE'] >= '2016-08-31') &  (training_data['DATE'] <= '2018-09-01')]\n",
        "\n",
        "    training_data = (\n",
        "        training_data\n",
        "        .sort_values(\"DATE\", ascending=False)\n",
        "        .groupby(['reviewerID', 'asin']).head(1)\n",
        "    )\n",
        "\n",
        "    reader = Reader(rating_scale=(0, 5))\n",
        "    training_data = training_data[['reviewerID', 'asin', 'overall']]\n",
        "    data = Dataset.load_from_df(training_data, reader=reader)\n",
        "\n",
        "    sim_options = {\n",
        "        'name': 'cosine',\n",
        "        'user_based': user_based  # compute similarities between items\n",
        "    }\n",
        "    algo_impl = algo(sim_options=sim_options)\n",
        "    trainset = data.build_full_trainset()\n",
        "    algo_impl.fit(trainset)\n",
        "\n",
        "    recommendation = {}\n",
        "    for user in users:\n",
        "        items_user_rated = set(training_data.loc[training_data['reviewerID'] == user]['asin'].to_list())\n",
        "        recommend_item_list = []\n",
        "        recommend_item_set = set()\n",
        "        for item in items_user_rated:\n",
        "            iid = algo_impl.trainset.to_inner_iid(item)\n",
        "            recommend_items_iid = algo_impl.get_neighbors(iid, k)\n",
        "            for sim_item_iid in recommend_items_iid:\n",
        "                item_raw_id = algo_impl.trainset.to_raw_iid(sim_item_iid)\n",
        "                if item_raw_id not in items_user_rated and item_raw_id not in recommend_item_set:\n",
        "                    recommend_item_list.append(item_raw_id)\n",
        "                    recommend_item_set.add(item_raw_id)\n",
        "\n",
        "            if len(recommend_item_list) >= k:\n",
        "                recommend_item_list = recommend_item_list[:k]\n",
        "                break\n",
        "        recommendation[user] = recommend_item_list\n",
        "        if len(recommendation[user]) < 10:\n",
        "          recommend_cates = []\n",
        "          recommend_cates = recommend_items(metadata[metadata['asin'].isin(ratings_trainings[ratings_trainings['reviewerID'] == user]['asin'].tolist())]['title'].tolist(), k)\n",
        "          [recommendation[user].append(recommend_cates[gg]) for gg in range(0, len(recommend_cates))]\n",
        "          [recommendation[user].append(top_10[gg]) for gg in range(0, 10-len(recommendation[user]))]\n",
        "    return recommendation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLQzONDb8eoD",
        "outputId": "667ba992-5361-41e3-be66-1fa086b34b5e"
      },
      "outputs": [
        {
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>recommender_list</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.133898</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.133898</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "  recommender_list     score\n0                0  0.133898\n1                1  0.133898"
          },
          "execution_count": 212,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate_result = {}\n",
        "n = 0\n",
        "R = [recommender_user, recommender_item]  #recommender_user, recommender_item, recommender_surprise\n",
        "for recommender in R: #\n",
        "  ratings_by_user = {}\n",
        "  # print(ratings_by_user)\n",
        "  ratings_by_user = recommender(ratings_trainings, users)\n",
        "  evaluate_result[str(n)] = evaluate(ratings_testings_by_user, ratings_by_user)\n",
        "  n += 1\n",
        "result = pd.DataFrame(list(evaluate_result.items()), columns=['recommender_list', 'score'])\n",
        "\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-QHjwrl8eoD",
        "outputId": "1cfd0937-87f1-4ae6-c97c-6ffe5a524bc3"
      },
      "outputs": [
        {
          "data": {
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>recommender_list</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.133898</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.133898</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
            "text/plain": "  recommender_list     score\n0                0  0.133898\n1                1  0.133898"
          },
          "execution_count": 213,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate_result = {}\n",
        "n = 0\n",
        "R = [recommender_user, recommender_item]  #recommender_user, recommender_item, recommender_surprise\n",
        "for recommender in R: #\n",
        "  ratings_by_user = {}\n",
        "  # print(ratings_by_user)\n",
        "  ratings_by_user = recommender(ratings_trainings_remove1, users)\n",
        "  evaluate_result[str(n)] = evaluate(ratings_testings_by_user, ratings_by_user)\n",
        "  n += 1\n",
        "result = pd.DataFrame(list(evaluate_result.items()), columns=['recommender_list', 'score'])\n",
        "\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9DnryIA8eoD"
      },
      "outputs": [],
      "source": [
        "evaluate_result = {}\n",
        "n = 0\n",
        "R = [recommender_surprise]  #recommender_user, recommender_item, recommender_surprise\n",
        "train_data = [ratings, ratings_trainings_remove1_surprise]\n",
        "for recommender in R: #\n",
        "  for data in train_data:  \n",
        "    ratings_by_user = {}\n",
        "    # print(ratings_by_user)\n",
        "    ratings_by_user = recommender(data, users)\n",
        "    evaluate_result[str(n)] = evaluate(ratings_testings_by_user, ratings_by_user)\n",
        "    n += 1\n",
        "result = pd.DataFrame(list(evaluate_result.items()), columns=['recommender_list', 'score'])\n",
        "\n",
        "result"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.8.5 64-bit (conda)",
      "name": "python385jvsc74a57bd0b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "orig_nbformat": 2,
    "colab": {
      "name": "Week3_A6.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}